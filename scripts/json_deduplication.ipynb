{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea150eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import altair as alt\n",
    "from altair import datum\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "import baltic as bt\n",
    "from augur import frequencies,frequency_estimators\n",
    "\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import unicodedata\n",
    "# import unidecode ## for removing diacritics from example geoJSON\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline ## used to smooth counts of lineages in each location at any given time\n",
    "from scipy.interpolate import interp1d ## used to linearly interpolate between data points used in colouring polygons\n",
    "from sklearn.decomposition import IncrementalPCA ## used to identify PCA1 when automatically producing a colour map\n",
    "\n",
    "import requests ## used to fetch examples from internet\n",
    "import json ## used for importing JSONs\n",
    "try:\n",
    "    from StringIO import StringIO as sio\n",
    "    from cStringIO import StringIO as csio\n",
    "except ImportError:\n",
    "    from io import StringIO as sio\n",
    "    from io import BytesIO as csio\n",
    "    \n",
    "\n",
    "\n",
    "from Bio import Phylo\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9acb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## unfortunately some of the mpox names are duplicated which makes baltic throw an error \n",
    "## use this code to depublicate and minimize it again!\n",
    "def make_unique_name(name, existing_names):\n",
    "    \"\"\"Generate a unique name by appending a counter if a name already exists.\"\"\"\n",
    "    counter = 1\n",
    "    new_name = name\n",
    "    while new_name in existing_names:\n",
    "        new_name = f\"{name}_{counter}\"\n",
    "        counter += 1\n",
    "    return new_name\n",
    "\n",
    "def process_node(node, existing_names):\n",
    "    \"\"\"Recursively process nodes in the JSON to ensure unique names.\"\"\"\n",
    "    if isinstance(node, dict):\n",
    "        if \"name\" in node:\n",
    "            original_name = node[\"name\"]\n",
    "            if original_name in existing_names:\n",
    "                new_name = make_unique_name(original_name, existing_names)\n",
    "                print(f\"Renaming {original_name} to {new_name}\")\n",
    "                node[\"name\"] = new_name\n",
    "            existing_names.add(node[\"name\"])\n",
    "        for key, value in node.items():\n",
    "            if isinstance(value, (dict, list)):\n",
    "                process_node(value, existing_names)\n",
    "    elif isinstance(node, list):\n",
    "        for item in node:\n",
    "            process_node(item, existing_names)\n",
    "\n",
    "def check_and_rename_nodes(input_file, output_file):\n",
    "    \"\"\"Process the JSON to deduplicate names and save in pretty format.\"\"\"\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    existing_names = set()\n",
    "    process_node(data, existing_names)\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)  # Save with pretty formatting\n",
    "\n",
    "    print(f\"Processing complete. Output written to {output_file}\")\n",
    "\n",
    "def minimize_json(input_file, minimized_output_file):\n",
    "    \"\"\"Minimize the JSON file by removing unnecessary formatting.\"\"\"\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    with open(minimized_output_file, 'w') as file:\n",
    "        json.dump(data, file)  # Save without pretty formatting\n",
    "\n",
    "    print(f\"Minimized JSON written to {minimized_output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '../mpox_build/phylogenetic/auspice/mpox_allcladeIIseqs.json'  # Replace with your actual input file path\n",
    "    output_file = '../mpox_build/phylogenetic/auspice/mpox_allcladeIIseqs_deduplicated_tree.json'  # Replace with your desired output file path\n",
    "    minimized_output_file = '../mpox_build/phylogenetic/auspice/mpox_allcladeIIseqs_deduplicated_tree_minimized.json'  # Output file for minimized JSON\n",
    "\n",
    "    # Deduplicate names and save the JSON\n",
    "    check_and_rename_nodes(input_file, output_file)\n",
    "\n",
    "    # Minimize the JSON file\n",
    "    minimize_json(output_file, minimized_output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
